{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNA1bKb8iTrZGW4kFu9Y8Cq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Endalebob/Deep-Learning-Lab/blob/main/DL_Lab_3_Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jin4kSX64Dvl"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "inp-4\n",
        "lay-3\n",
        "node-18\n",
        "outp-3\n",
        "h-act-relu-sigmoid\n",
        "o-act-softmax\n",
        "loss=c.c.el\n",
        "accuracy\n",
        "'''"
      ],
      "metadata": {
        "id": "MPxm1G7o5Xyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseLayer:\n",
        "  def __init__(self,n_features,n_nodes):\n",
        "    self.weights = torch.rand((n_features,n_nodes))\n",
        "    self.bias = torch.zeros((1,n_nodes))\n",
        "  def forward(self,inputs):\n",
        "    self.output = torch.matmul(inputs,self.weights)+self.bias"
      ],
      "metadata": {
        "id": "zYk2qa7V4WiE"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.rand((5,4))\n",
        "inputs -= 0.3\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf-biKbV5Uae",
        "outputId": "49ca7ba7-32e5-4adf-bd65-c32e68be114a"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5850,  0.5996,  0.6602,  0.5218],\n",
              "        [ 0.4616,  0.4963,  0.4278,  0.6904],\n",
              "        [ 0.1638,  0.5229,  0.3972,  0.4802],\n",
              "        [-0.1106,  0.4565, -0.1625,  0.1749],\n",
              "        [-0.1141, -0.1488,  0.1672,  0.3371]])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationReLU(torch.nn.Module):\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        ReLU function:\n",
        "        ReLU(x) = max(0, x)\n",
        "\n",
        "        Args:\n",
        "            inputs (torch.Tensor): Input tensor.\n",
        "        \"\"\"\n",
        "        # Step 1: Compute the element-wise maximum with 0\n",
        "        relu_output = torch.max(torch.tensor(0), inputs)\n",
        "\n",
        "        return relu_output\n"
      ],
      "metadata": {
        "id": "nrpv11c3_fV9"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer1 = DenseLayer(len(inputs[0]),18)\n",
        "layer1.forward(inputs)\n",
        "relu = ActivationReLU()\n",
        "layer1_output = relu.forward(layer1.output)\n",
        "layer1_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B8oGLMu5xK7",
        "outputId": "c89a678a-4ecd-4648-9843-7b12ee8a5e87"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7490, 1.0608, 1.5070, 1.4546, 1.3501, 0.7518, 0.7841, 1.5346, 1.2480,\n",
              "         1.1036, 1.1595, 0.8110, 1.3889, 0.9876, 1.2407, 1.1040, 1.6128, 1.3730],\n",
              "        [0.6254, 1.0325, 1.2613, 1.3298, 1.2897, 0.6466, 0.7021, 1.3412, 1.1072,\n",
              "         0.9177, 1.1232, 0.6661, 1.0798, 0.7708, 1.0064, 0.8681, 1.4669, 1.1118],\n",
              "        [0.4802, 0.6809, 1.0388, 0.9490, 0.9433, 0.5534, 0.5696, 1.0924, 0.9939,\n",
              "         0.7324, 0.8863, 0.6057, 0.8792, 0.7553, 0.7682, 0.6005, 0.9862, 0.8624],\n",
              "        [0.0000, 0.2163, 0.3260, 0.1595, 0.1560, 0.3125, 0.3000, 0.2868, 0.4279,\n",
              "         0.2131, 0.1998, 0.2626, 0.1081, 0.3672, 0.2401, 0.0350, 0.0785, 0.1752],\n",
              "        [0.1707, 0.0959, 0.0715, 0.2337, 0.3465, 0.0000, 0.0000, 0.2162, 0.1472,\n",
              "         0.0310, 0.3579, 0.0096, 0.0843, 0.0000, 0.0000, 0.0000, 0.2546, 0.0349]])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationSigmoid(torch.nn.Module):\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Sigmoid function:\n",
        "        Sigmoid(x) = 1 / (1 + exp(-x))\n",
        "\n",
        "        Args:\n",
        "            inputs (torch.Tensor): Input tensor.\n",
        "        \"\"\"\n",
        "        # Step 1: Compute the element-wise exponentiation\n",
        "        exp_inputs = torch.exp(-inputs)\n",
        "\n",
        "        # Step 2: Compute the element-wise reciprocal (1 / (1 + exp(-x)))\n",
        "        sigmoid_output = 1 / (1 + exp_inputs)\n",
        "\n",
        "        return sigmoid_output\n"
      ],
      "metadata": {
        "id": "EB2TiqnUDNTh"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer2 = DenseLayer(len(layer1_output[0]),18)\n",
        "layer2.forward(layer1_output)\n",
        "sigmoid = ActivationSigmoid()\n",
        "layer2_output = sigmoid.forward(layer2.output)\n",
        "layer2_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WqyhFTq6UlF",
        "outputId": "e4bdcb28-34a7-44f1-963f-25c99cab952b"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 1.0000,\n",
              "         0.9998, 0.9999, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 0.9999],\n",
              "        [0.9998, 0.9998, 0.9999, 1.0000, 0.9999, 0.9999, 0.9997, 0.9998, 0.9998,\n",
              "         0.9993, 0.9998, 0.9999, 1.0000, 0.9999, 0.9996, 1.0000, 0.9998, 0.9997],\n",
              "        [0.9984, 0.9989, 0.9995, 0.9996, 0.9992, 0.9995, 0.9982, 0.9988, 0.9989,\n",
              "         0.9968, 0.9986, 0.9994, 0.9996, 0.9993, 0.9976, 0.9997, 0.9988, 0.9983],\n",
              "        [0.8324, 0.8766, 0.8922, 0.8769, 0.8823, 0.8893, 0.8185, 0.8611, 0.8838,\n",
              "         0.8095, 0.8488, 0.8861, 0.8869, 0.8778, 0.8389, 0.8819, 0.8592, 0.8366],\n",
              "        [0.7525, 0.6815, 0.7697, 0.7914, 0.7369, 0.7873, 0.7330, 0.7088, 0.7443,\n",
              "         0.6995, 0.6899, 0.7509, 0.7357, 0.7556, 0.6909, 0.7901, 0.7171, 0.7100]])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationSoftmax(torch.nn.Module):\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Softmax function:\n",
        "        Softmax(x)_i = exp(x_i) / sum(exp(x))\n",
        "\n",
        "        Args:\n",
        "            inputs (torch.Tensor): Input tensor of shape (batch_size, num_classes).\n",
        "        \"\"\"\n",
        "        # Step 1: Compute the maximum value along axis 1 (columns)\n",
        "        max_inputs, _ = torch.max(inputs, dim=1, keepdim=True)\n",
        "\n",
        "        # Step 2: Subtract the maximum to prevent overflow\n",
        "        inputs -= max_inputs\n",
        "\n",
        "        # Step 3: Compute element-wise exponentiation\n",
        "        exp_inputs = torch.exp(inputs)\n",
        "\n",
        "        # Step 4: Compute the sum along axis 1 (columns) to get the denominator\n",
        "        sum_exp_inputs = torch.sum(exp_inputs, dim=1, keepdim=True)\n",
        "\n",
        "        # Step 5: Element-wise division of exp_inputs by the sum_exp_inputs\n",
        "        softmax_output = exp_inputs / sum_exp_inputs\n",
        "\n",
        "        return softmax_output\n"
      ],
      "metadata": {
        "id": "Q-IVAnBiD6sc"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer3 = DenseLayer(len(layer2.output[0]),18)\n",
        "layer3.forward(layer2.output)\n",
        "relu = ActivationReLU()\n",
        "layer3_output = relu.forward(layer3.output)\n",
        "layer3_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T7USzFP7gFR",
        "outputId": "00157a36-a085-4f18-ed28-66c096084409"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 92.9062,  91.3023,  81.1489,  72.0489,  70.7286,  80.8314,  87.6328,\n",
              "          98.5299,  94.6837,  99.7296,  80.1876,  69.0602,  97.4812,  93.5821,\n",
              "          94.6993,  95.8192, 108.1552, 102.9164],\n",
              "        [ 80.5697,  79.1961,  70.2199,  62.4947,  61.3633,  70.2345,  75.8674,\n",
              "          85.3675,  82.0248,  86.4670,  69.5151,  59.7327,  84.3829,  81.2252,\n",
              "          82.1179,  83.2936,  93.7694,  89.3328],\n",
              "        [ 63.0180,  61.9796,  54.9211,  48.9371,  47.8667,  54.8944,  59.4667,\n",
              "          66.9188,  64.1331,  67.6857,  54.5298,  46.8707,  66.1833,  63.3995,\n",
              "          64.2565,  65.0245,  73.3506,  69.9697],\n",
              "        [ 16.7309,  16.5925,  14.5185,  12.8387,  12.5281,  14.4617,  15.8468,\n",
              "          18.0508,  16.9563,  18.0708,  14.8696,  12.5817,  17.7149,  16.7402,\n",
              "          17.0683,  17.3756,  19.6313,  18.5823],\n",
              "        [  9.4021,   9.1546,   8.0120,   7.5401,   7.1745,   8.4483,   8.7398,\n",
              "           9.7512,   9.4368,   9.9994,   7.8442,   6.7883,   9.6306,   9.4957,\n",
              "           9.6160,   9.7492,  10.7514,  10.6737]])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = DenseLayer(len(layer3.output[0]),3)\n",
        "output.forward(layer3.output)\n",
        "softmax = ActivationSoftmax()\n",
        "\n",
        "final_output = softmax.forward(output.output)\n",
        "final_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWRwoLZD73zA",
        "outputId": "45a4a0f9-ed2c-4106-cf3c-6e7e5a3527fc"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000e+00, 1.2303e-24, 1.0000e+00],\n",
              "        [5.4230e-43, 1.6536e-21, 1.0000e+00],\n",
              "        [9.0897e-34, 6.4474e-17, 1.0000e+00],\n",
              "        [1.2733e-09, 5.7412e-05, 9.9994e-01],\n",
              "        [1.6194e-05, 3.4431e-03, 9.9654e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argmax(final_output,dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afGcUOwK8LDd",
        "outputId": "237c305e-f162-4ccb-c513-604a89246219"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LossCategoricalCrossEntropy:\n",
        "    def forward(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Categorical Cross-Entropy Loss function for classification tasks.\n",
        "\n",
        "        Args:\n",
        "            y_pred (torch.Tensor): Predicted class probabilities (e.g., output from softmax).\n",
        "            y_true (torch.Tensor): True class labels as one-hot encoded vectors.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Categorical Cross-Entropy Loss.\n",
        "        \"\"\"\n",
        "        # Calculate the negative log likelihood of the true class labels\n",
        "        loss = -torch.sum(y_true * torch.log(y_pred + 1e-15)) / y_true.size(0)\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "bXfjYQl59KXc"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define your true class labels in one-hot encoded format\n",
        "true_labels = torch.tensor([[0, 0, 1],  # Row 0: Correct prediction is class 2\n",
        "                            [0, 1, 0],  # Row 1: Correct prediction is class 1\n",
        "                            [0, 0, 1],  # Row 2: Correct prediction is class 2\n",
        "                            [1, 0, 0],\n",
        "                            [0, 0, 1]]) # Row 4: Correct prediction is class 0\n",
        "\n",
        "# Example of predicted class probabilities (output from your final layer)\n",
        "predicted_probs = final_output\n",
        "\n",
        "# Create the LossCategoricalCrossEntropy module\n",
        "loss_fn = LossCategoricalCrossEntropy()\n",
        "\n",
        "# Calculate the loss\n",
        "loss = loss_fn.forward(predicted_probs, true_labels)\n",
        "\n",
        "print(\"Categorical Cross-Entropy Loss:\", loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBKXhlTKOXgJ",
        "outputId": "9f4ae922-aaf7-45d0-afe0-4c0dd6073905"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical Cross-Entropy Loss: 11.004776000976562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Accuracy(nn.Module):\n",
        "    def forward(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Calculate the classification accuracy.\n",
        "\n",
        "        Args:\n",
        "            y_pred (torch.Tensor): Predicted class probabilities (e.g., output from softmax).\n",
        "            y_true (torch.Tensor): True class labels as one-hot encoded vectors.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Classification accuracy.\n",
        "        \"\"\"\n",
        "        # Get the predicted class labels by finding the index of the maximum probability\n",
        "        pred_labels = torch.argmax(y_pred, dim=1)\n",
        "\n",
        "        # Get the true class labels by finding the index of the one-hot encoded vectors\n",
        "        true_labels = torch.argmax(y_true, dim=1)\n",
        "\n",
        "        # Compare predicted labels with true labels and calculate accuracy\n",
        "        correct_predictions = torch.eq(pred_labels, true_labels).float()\n",
        "        accuracy = torch.mean(correct_predictions)\n",
        "\n",
        "        return accuracy\n"
      ],
      "metadata": {
        "id": "h4D8dtphPbRn"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy\n",
        "accuracy_class = Accuracy()\n",
        "accuracy = accuracy_class.forward(predicted_probs, true_labels)\n",
        "\n",
        "print(\"Accuracy:\", accuracy.item())"
      ],
      "metadata": {
        "id": "kPrWptUpQLDO",
        "outputId": "967a32e2-35dd-4802-96c1-b34be39d5661",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6000000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aNQMNyBnQdnB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}