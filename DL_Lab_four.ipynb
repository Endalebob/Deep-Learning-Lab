{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjOVHeiasbaBXfj/V7XrnX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Endalebob/Deep-Learning-Lab/blob/main/DL_Lab_four.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Kw8Q-U_1BefR"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseLayer:\n",
        "  # Layer initialization\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    # Initialize weights and biases\n",
        "    self.weights = 0.01 * torch.rand(n_inputs, n_neurons)\n",
        "    self.biases = torch.zeros((1, n_neurons))\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    # Calculate output values from inputs, weights and biases\n",
        "    self.output = torch.matmul(inputs, self.weights) + self.biases"
      ],
      "metadata": {
        "id": "ZeiZPsegBmdx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation_ReLU:\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    self.output = torch.max(torch.tensor(0),inputs)"
      ],
      "metadata": {
        "id": "gbGw720EC3TI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation_Sigmoid:\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    self.output = 1 / (1 + torch.exp(-inputs))\n",
        "    return self.output"
      ],
      "metadata": {
        "id": "SN04sLzMEKHt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation_Softmax:\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    # Get unnormalized probabilities\n",
        "    exp_values = torch.exp(inputs - torch.max(inputs, axis=1, keepdim=True).values)\n",
        "    # Normalize them for each sample\n",
        "    probabilities = exp_values / torch.sum(exp_values, axis=1, keepdim=True)\n",
        "    self.output = probabilities"
      ],
      "metadata": {
        "id": "AQIIZiwzEQMX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Accuracy():\n",
        "  def calculate(self, y_pred, y_true):\n",
        "    predictions = torch.argmax(y_pred, axis=1)\n",
        "    if len(y_true.shape) == 2:\n",
        "      y_true = torch.argmax(y_true, axis=1)\n",
        "    accuracy = torch.mean((predictions == y_true).float())\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "zzWuE3jHEZoR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_squared_error(y_true, y_pred):\n",
        "    # Calculate Mean Squared Error\n",
        "    loss = torch.mean((y_true - y_pred) ** 2)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "zjZXua-YPUow"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input, Output Data\n",
        "X = torch.tensor([[0.1, 0.2], [0.4, 0.5], [0.7, 0.8]])  # Example input data with 2 features\n",
        "y = torch.tensor([[0.3, 0.4], [0.6, 0.7], [0.9, 1.0]])  # Example output data with 2 targets"
      ],
      "metadata": {
        "id": "RJf3ESlIOFAz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define network architecture\n",
        "hidden_layer = DenseLayer(2, 4)  # 2 input features, 4 neurons in hidden layer\n",
        "output_layer = DenseLayer(4, 2)  # 4 neurons in hidden layer, 2 output neurons\n",
        "activation_sigmoid = Activation_Sigmoid()"
      ],
      "metadata": {
        "id": "-CD8OCOWOl2r"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "learning_rate = 0.01\n",
        "loss_threshold = 0.0001\n",
        "epochs = 10000"
      ],
      "metadata": {
        "id": "T7kZJmLjOpXC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for forward pass\n",
        "def forward_pass(x):\n",
        "    hidden_layer.forward(x)\n",
        "    hidden_activation = activation_sigmoid.forward(hidden_layer.output)\n",
        "    output_layer.forward(hidden_activation)\n",
        "    return output_layer.output"
      ],
      "metadata": {
        "id": "V8FrdBatOt20"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for backpropagation\n",
        "def back_prop(fp):\n",
        "    # Calculate the error in the output layer\n",
        "    output_error = fp - y\n",
        "    output_delta = output_error  # Gradient of the loss w.r.t. output layer's\n",
        "\n",
        "    # Backpropagate the output delta to the hidden layer\n",
        "    hidden_error = torch.matmul(output_delta, output_layer.weights.T)\n",
        "\n",
        "    # Calculate the derivative of the hidden layer's activation function\n",
        "    hidden_activation_derivative = activation_sigmoid.forward(hidden_layer.output) * (\n",
        "        1 - activation_sigmoid.forward(hidden_layer.output)\n",
        "    )\n",
        "\n",
        "    # Compute the delta for the hidden layer\n",
        "    hidden_delta = hidden_error * hidden_activation_derivative  # Gradient of the loss w.r.t. hidden layer's pre-activation values\n",
        "\n",
        "    # Update output layer weights and biases using gradient descent\n",
        "    output_layer.weights -= learning_rate * torch.matmul(\n",
        "        activation_sigmoid.output.T, output_delta\n",
        "    )  # Update rule for output layer weights\n",
        "    output_layer.biases -= learning_rate * torch.sum(output_delta, axis=0, keepdim=True)  # Update rule for output layer biases\n",
        "\n",
        "    # Update hidden layer weights and biases using gradient descent\n",
        "    hidden_layer.weights -= learning_rate * torch.matmul(X.T, hidden_delta)  # Update rule for hidden layer weights\n",
        "    hidden_layer.biases -= learning_rate * torch.sum(hidden_delta, axis=0, keepdim=True)  # Update rule for hidden layer biases\n"
      ],
      "metadata": {
        "id": "wghJUNBBPEMm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    predictions = forward_pass(X)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = mean_squared_error(y, predictions)\n",
        "\n",
        "    # Backward pass (Gradient Descent)\n",
        "    back_prop(predictions)\n",
        "\n",
        "    if loss < loss_threshold:\n",
        "        print(f\"Training stopped at epoch {epoch + 1} with Loss: {loss.item()}\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STXHOymfPIVF",
        "outputId": "8d033c84-da82-476c-ee10-20a86839892f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training stopped at epoch 7459 with Loss: 9.992767445510253e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After training, use the model for predictions\n",
        "final_predictions = forward_pass(X)\n",
        "print(\"Final loss:\", loss)\n",
        "print(\"Final prediction:\",final_predictions)\n",
        "print(\"Target value:\",y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeQaTPHnPLxz",
        "outputId": "7e65e3aa-0125-4de4-c845-4e19a496ac28"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final loss: tensor(9.9928e-05)\n",
            "Final prediction: tensor([[0.3065, 0.4045],\n",
            "        [0.6097, 0.7097],\n",
            "        [0.8860, 0.9877]])\n",
            "Target value: tensor([[0.3000, 0.4000],\n",
            "        [0.6000, 0.7000],\n",
            "        [0.9000, 1.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p2jawyjzQFmE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}